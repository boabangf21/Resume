{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc4f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as layers\n",
    "from data_generator import DataGenerator\n",
    "import pandas as pd\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import sys\n",
    "print(os.getcwd())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= sys.argv[1]\n",
    "import tensorflow as tf\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "import numpy as np\n",
    "#from keras.datasets import cifar10\n",
    "import keras.callbacks as callbacks\n",
    "#import keras.utils.np_utils as kutils\n",
    "from tensorflow.keras import utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "#from wide_resnet import WRNModel\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "#from keras.utils import plot_model\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# parts of the code were adapted from https://github.com/jemiar/surgery-gesture-recog\n",
    "# parts of the code were adapted from https://github.com/yashkant/padam-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ad7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ea1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = '/Users/boabangfrancis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f136c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"/Users/boabangfrancis/Suturing.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"/Users/boabangfrancis/Suturing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#h=[]\n",
    "#for i in os.listdir('/Users/boabangfrancis/transcription/transcription/'):\n",
    "#    if i.startswith('S'):\n",
    " #       h.append(i)\n",
    "#transcriptions=sorted(h[16:17])\n",
    "transcriptions=['Suturing_B001.csv', 'Suturing_C001.csv','Suturing_D001.csv','Suturing_E001.csv', 'Suturing_G001.csv','Suturing_H001.csv','Suturing_I001.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9002eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(fromarray=transcriptions, height=240, width=320, folder='data_action/', idnumber=1):\n",
    "    # array to store ids of normal blocks\n",
    "    normals = []\n",
    "    # array to store ids of transit blocks\n",
    "    transits = []\n",
    "    # dictionary to store target y value (class) of each block\n",
    "    labels = {}\n",
    "    os.chdir(base_directory + 'Suturing/Suturing/video/')\n",
    "    # for each element in fromarray (store video file names)\n",
    "    for arr in fromarray:\n",
    "        # use CV2 to capture the video file\n",
    "        cap = cv2.VideoCapture(arr[:][:-4] + '_capture1.avi')\n",
    "        i = 1\n",
    "        # Initialize numpy array to store frames of Red, Green, Blue channels of video\n",
    "        red_frames = np.empty((0, height, width))\n",
    "        green_frames = np.empty((0, height, width))\n",
    "        blue_frames = np.empty((0, height, width))\n",
    "        # while reading the capture, only store 1 frame for every 3 frames\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "            if i%3 == 1:\n",
    "                # Resize the frame to reduce the computation during training\n",
    "                frame = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "                # Cast the frame as a numpy array\n",
    "                f = np.asarray(frame)\n",
    "                # Update the color of frame from BGR to RGB\n",
    "                f = cv2.cvtColor(f, cv2.COLOR_BGR2RGB)\n",
    "                # Apprend frame to its appropriate channel\n",
    "                red_frames = np.append(red_frames, np.expand_dims(f[:,:,0], axis=0), axis=0)\n",
    "                green_frames = np.append(green_frames, np.expand_dims(f[:,:,1], axis=0), axis=0)\n",
    "                blue_frames = np.append(blue_frames, np.expand_dims(f[:,:,2], axis=0), axis=0)\n",
    "            i += 1\n",
    "        # Release the capture when finishing reading\n",
    "        cap.release()\n",
    "        # Normalize the value of each element to range [0, 1]\n",
    "        red_frames = red_frames / 255.0\n",
    "        green_frames = green_frames / 255.0\n",
    "        blue_frames = blue_frames / 255.0\n",
    "        # For each transciption (transcribe where each gesture starts and ends)\n",
    "        df= pd.read_csv(base_directory + 'transcription/transcription/' + str(arr[:-4]) + '.csv') \n",
    "        arr_gesture=np.array(df)\n",
    "        for k, t in enumerate(arr_gesture[10:-4]):\n",
    "            # Save the normal block\n",
    "            # Calculate the left most frame of 1 gesture\n",
    "            left = (int((t[0])) + 1) // 3\n",
    "            # Calculate the right most frame of 1 gesture\n",
    "            right = (int((t[1])) - 1) // 3\n",
    "            # Calculate the number of normal blocks in a gesture\n",
    "            num_blocks = (right - left + 1) // 10\n",
    "            for index in range(num_blocks):\n",
    "                block = np.expand_dims(red_frames[left+index*10:left+(index+1)*10,:,:], axis=3)\n",
    "                block = np.append(block, np.expand_dims(green_frames[left+index*10:left+(index+1)*10,:,:], axis=3), axis=3)\n",
    "                block = np.append(block, np.expand_dims(blue_frames[left+index*10:left+(index+1)*10,:,:], axis=3), axis=3)\n",
    "            # Store normal block\n",
    "                npy_name = 'id_' + str(idnumber)\n",
    "                temp_obj = {'id': npy_name, 'file': arr[:], 'label': 0}\n",
    "                normals.append(npy_name)\n",
    "                labels[npy_name] = 0\n",
    "                np.save(base_directory + folder + npy_name + '.npy', block)\n",
    "                idnumber += 1\n",
    "\n",
    "            # Save transit blocks\n",
    "            if k < (len(arr_gesture[10:-4]) - 1):\n",
    "                # Each transit block has the last 5 frames of 1 gesture and the 1st 5 frames of the next gesture\n",
    "                # Calculate the left most frame of a transit block\n",
    "                ind = (int(t[1]) - 1) // 3 - 4\n",
    "                block = np.expand_dims(red_frames[ind:ind+10,:,:], axis=3)\n",
    "                block = np.append(block, np.expand_dims(green_frames[ind:ind+10,:,:], axis=3), axis=3)\n",
    "                block = np.append(block, np.expand_dims(blue_frames[ind:ind+10,:,:], axis=3), axis=3)\n",
    "                # Store transit block\n",
    "                #npy_name = 'id_' + str(idnumber)\n",
    "                temp_obj = {'id': npy_name, 'file': arr[:], 'label': 1}\n",
    "                normals.append(npy_name)\n",
    "                labels[npy_name] = 1\n",
    "                np.save(base_directory + folder + npy_name + '.npy', block)\n",
    "                idnumber += 1\n",
    "\n",
    "    return normals, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(height=240, width=320):\n",
    "    # shape of input: 1 block has 10 frames x height x width x 3 channels (RGB)\n",
    "    input = tf.keras.Input((10, height, width, 3))\n",
    "\n",
    "    # 1st Conv3D block includes Conv3D with 8 filters, MaxPool3D and BatchNormalization\n",
    "    x = layers.Conv3D(filters=8, kernel_size=(3,3,3), activation='relu')(input)\n",
    "    x = layers.MaxPool3D(pool_size=(2,2,2))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # 2nd Conv3D block includes Conv3D with 16 filters, MaxPool3D and BatchNormalization\n",
    "    x = layers.Conv3D(filters=16, kernel_size=(3,3,3), activation='relu')(x)\n",
    "    x = layers.MaxPool3D(pool_size=(2,2,2))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # 3rd Conv3D block includes Conv3D with 32 filters, MaxPool3D and BatchNormalization\n",
    "    x = layers.Conv3D(filters=32, kernel_size=(3,3,3), activation='relu')(input)\n",
    "    x = layers.MaxPool3D(pool_size=(1,2,2))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Fully-connected block includes GlobalAveragePooling3D, Fully-Connected layer with 512 units and DropOut for Regularization\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.7)(x)\n",
    "\n",
    "    # output shape (1,) produces value between [0, 1]\n",
    "    output = layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(input, output, name='3DCNN')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13483ac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaca2e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Create data generator for training and validation\n",
    "\n",
    "#normals, labels =save_data(fromarray=transcriptions, height=240, width=320, folder='data_action/', idnumber=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780621e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = {\n",
    "    \n",
    "    \n",
    "    'proposed_ASGD': {\n",
    "        'weight_decay': 0.0001,\n",
    "        'lr_min': 0.00001,\n",
    "        'lr_max':0.0001,\n",
    "        #'lr': 0, # dummy value\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.99,\n",
    "        'color': 'red',\n",
    "        'linestyle':'-'\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    'padam': {\n",
    "        'weight_decay': 0.0001,\n",
    "        'lr_max': 0.001,\n",
    "        'p': 0.2,\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.999,\n",
    "        'color': 'darkred',\n",
    "        'linestyle':'-'\n",
    "    },\n",
    "    'adam': {\n",
    "        'weight_decay': 0.0001,\n",
    "        'lr_min': 0.00001,\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.99,\n",
    "        'color': 'orange',\n",
    "        'linestyle':'--'\n",
    "    },\n",
    "    'adamw': {\n",
    "        'weight_decay': 0.025,\n",
    "        'lr_min': 0.00001,\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.99,\n",
    "        'color': 'magenta',\n",
    "        'linestyle':'--'\n",
    "    },\n",
    "    'amsgrad': {\n",
    "        'weight_decay': 0.0001,\n",
    "        'lr_min': 0.00001,\n",
    "        'b1': 0.9,\n",
    "        'b2': 0.99,\n",
    "        'color' : 'darkgreen',\n",
    "        'linestyle':'-.'\n",
    "    },\n",
    "    'sgd': {\n",
    "        'weight_decay': 0.0005,\n",
    "        'lr_max': 0.0001,\n",
    "        'm': 0.9,\n",
    "        'color': 'blue',\n",
    "        'linestyle':'-'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1658b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "#ham_messages=[{'id_1','id_1','id_1','id_1','id_3','id_1','id_3','id_2','id_1','id_1','id_4','id_1','id_1'}]\n",
    "ham_downsample = resample([labels],\n",
    "             replace=True,\n",
    "             n_samples=len([labels]),\n",
    "             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "label={'id_1': 0,\n",
    "  'id_2': 0,\n",
    "  'id_3': 0,\n",
    "  'id_4': 0,\n",
    "  'id_5': 0,\n",
    "  'id_6': 0,\n",
    "  'id_7': 0,\n",
    "  'id_8': 0,\n",
    "  'id_9': 0,\n",
    "  'id_10': 0,\n",
    "  'id_11': 0,\n",
    "  'id_12': 0,\n",
    "  'id_13': 0,\n",
    "  'id_14': 0,\n",
    "  'id_15': 0,\n",
    "  'id_16': 1,\n",
    "  'id_18': 0,\n",
    "  'id_19': 0,\n",
    "  'id_20': 0,\n",
    "  'id_21': 0,\n",
    "  'id_22': 0,\n",
    "  'id_23': 0,\n",
    "  'id_24': 1,\n",
    "  'id_26': 0,\n",
    "  'id_27': 0,\n",
    "  'id_28': 0,\n",
    "  'id_29': 0,\n",
    "  'id_30': 0,\n",
    "  'id_31': 1,\n",
    "  'id_33': 0,\n",
    "  'id_34': 1,\n",
    "  'id_36': 0,\n",
    "  'id_37': 0,\n",
    "  'id_38': 0,\n",
    "  'id_39': 0,\n",
    "  'id_40': 0,\n",
    "  'id_41': 0,\n",
    "  'id_42': 1,\n",
    "  'id_44': 0,\n",
    "  'id_45': 0,\n",
    "  'id_46': 0,\n",
    "  'id_47': 0,\n",
    "  'id_48': 0,\n",
    "  'id_49': 1,\n",
    "  'id_51': 0,\n",
    "  'id_52': 0,\n",
    "  'id_53': 0,\n",
    "  'id_54': 0,\n",
    "  'id_55': 1,\n",
    "  'id_57': 0,\n",
    "  'id_58': 0,\n",
    "  'id_59': 0,\n",
    "  'id_60': 0,\n",
    "  'id_61': 0,\n",
    "  'id_62': 0,\n",
    "  'id_63': 0,\n",
    "  'id_64': 0,\n",
    "  'id_65': 0,\n",
    "  'id_66': 0,\n",
    "  'id_67': 1,\n",
    "  'id_69': 0,\n",
    "  'id_70': 0,\n",
    "  'id_71': 0,\n",
    "  'id_72': 0,\n",
    "  'id_73': 0,\n",
    "  'id_74': 0,\n",
    "  'id_75': 0,\n",
    "  'id_76': 0,\n",
    "  'id_77': 0,\n",
    "  'id_78': 0,\n",
    "  'id_79': 1,\n",
    "  'id_81': 0,\n",
    "  'id_82': 0,\n",
    "  'id_83': 0,\n",
    "  'id_84': 0,\n",
    "  'id_85': 0,\n",
    "  'id_86': 0,\n",
    "  'id_87': 0,\n",
    "  'id_88': 0,\n",
    "  'id_89': 0,\n",
    "  'id_90': 1,\n",
    "  'id_92': 1,\n",
    "  'id_94': 0,\n",
    "  'id_95': 0,\n",
    "  'id_96': 0,\n",
    "  'id_97': 0,\n",
    "  'id_98': 0,\n",
    "  'id_99': 0,\n",
    "  'id_100': 0,\n",
    "  'id_101': 0,\n",
    "  'id_102': 0,\n",
    "  'id_103': 0,\n",
    "  'id_104': 1,\n",
    "  'id_106': 0,\n",
    "  'id_107': 0,\n",
    "  'id_108': 0,\n",
    "  'id_109': 1,\n",
    "  'id_111': 0,\n",
    "  'id_112': 0,\n",
    "  'id_113': 0,\n",
    "  'id_114': 0,\n",
    "  'id_115': 0,\n",
    "  'id_116': 0,\n",
    "  'id_117': 0,\n",
    "  'id_118': 1,\n",
    "  'id_120': 0,\n",
    "  'id_121': 0,\n",
    "  'id_122': 1,\n",
    "  'id_124': 0,\n",
    "  'id_125': 0,\n",
    "  'id_126': 0,\n",
    "  'id_127': 0,\n",
    "  'id_128': 0,\n",
    "  'id_129': 0,\n",
    "  'id_130': 1,\n",
    "  'id_132': 0,\n",
    "  'id_133': 0,\n",
    "  'id_134': 0,\n",
    "  'id_135': 0,\n",
    "  'id_136': 1,\n",
    "  'id_138': 0,\n",
    "  'id_139': 0,\n",
    "  'id_140': 0,\n",
    "  'id_141': 0,\n",
    "  'id_142': 1,\n",
    "  'id_144': 0,\n",
    "  'id_145': 1,\n",
    "  'id_147': 0,\n",
    "  'id_148': 0,\n",
    "  'id_149': 1,\n",
    "  'id_151': 0,\n",
    "  'id_152': 0,\n",
    "  'id_153': 0,\n",
    "  'id_154': 0,\n",
    "  'id_155': 0,\n",
    "  'id_156': 1,\n",
    "  'id_158': 1,\n",
    "  'id_160': 1,\n",
    "  'id_162': 0,\n",
    "  'id_163': 0,\n",
    "  'id_164': 0,\n",
    "  'id_165': 0,\n",
    "  'id_166': 0,\n",
    "  'id_167': 0,\n",
    "  'id_168': 0,\n",
    "  'id_169': 1,\n",
    "  'id_171': 0,\n",
    "  'id_172': 0,\n",
    "  'id_173': 0,\n",
    "  'id_174': 0,\n",
    "  'id_175': 0,\n",
    "  'id_176': 0,\n",
    "  'id_177': 0,\n",
    "  'id_178': 0,\n",
    "  'id_179': 0,\n",
    "  'id_180': 1,\n",
    "  'id_182': 0,\n",
    "  'id_183': 0,\n",
    "  'id_184': 0,\n",
    "  'id_185': 0,\n",
    "  'id_186': 0,\n",
    "  'id_187': 0,\n",
    "  'id_188': 0,\n",
    "  'id_189': 1,\n",
    "  'id_191': 0,\n",
    "  'id_192': 0,\n",
    "  'id_193': 0,\n",
    "  'id_194': 0,\n",
    "  'id_195': 0,\n",
    "  'id_196': 1,\n",
    "  'id_198': 0,\n",
    "  'id_199': 0,\n",
    "  'id_200': 0,\n",
    "  'id_201': 1,\n",
    "  'id_203': 0,\n",
    "  'id_204': 0,\n",
    "  'id_205': 0,\n",
    "  'id_206': 1,\n",
    "  'id_208': 0,\n",
    "  'id_209': 0,\n",
    "  'id_210': 0,\n",
    "  'id_211': 0,\n",
    "  'id_212': 0,\n",
    "  'id_213': 0,\n",
    "  'id_214': 0,\n",
    "  'id_215': 0,\n",
    "  'id_216': 0,\n",
    "  'id_217': 0,\n",
    "  'id_218': 0,\n",
    "  'id_219': 0,\n",
    "  'id_220': 1,\n",
    "  'id_222': 1,\n",
    "  'id_224': 0,\n",
    "  'id_225': 1,\n",
    "  'id_227': 0,\n",
    "  'id_228': 0,\n",
    "  'id_229': 0,\n",
    "  'id_230': 0,\n",
    "  'id_231': 0,\n",
    "  'id_232': 0,\n",
    "  'id_233': 0,\n",
    "  'id_234': 0,\n",
    "  'id_235': 0,\n",
    "  'id_236': 0,\n",
    "  'id_237': 0,\n",
    "  'id_238': 0,\n",
    "  'id_239': 0,\n",
    "  'id_240': 0,\n",
    "  'id_241': 1,\n",
    "  'id_243': 0,\n",
    "  'id_244': 0,\n",
    "  'id_245': 0,\n",
    "  'id_246': 0,\n",
    "  'id_247': 0,\n",
    "  'id_248': 1,\n",
    "  'id_250': 0,\n",
    "  'id_251': 0,\n",
    "  'id_252': 0,\n",
    "  'id_253': 1,\n",
    "  'id_255': 0,\n",
    "  'id_256': 0,\n",
    "  'id_257': 0,\n",
    "  'id_258': 1,\n",
    "  'id_260': 0,\n",
    "  'id_261': 0,\n",
    "  'id_262': 0,\n",
    "  'id_263': 0,\n",
    "  'id_264': 1,\n",
    "  'id_266': 0,\n",
    "  'id_267': 0,\n",
    "  'id_268': 0,\n",
    "  'id_269': 1,\n",
    "  'id_271': 0,\n",
    "  'id_272': 0,\n",
    "  'id_273': 0,\n",
    "  'id_274': 0,\n",
    "  'id_275': 1,\n",
    "  'id_277': 0,\n",
    "  'id_278': 0,\n",
    "  'id_279': 0,\n",
    "  'id_280': 0,\n",
    "  'id_281': 0,\n",
    "  'id_282': 0,\n",
    "  'id_283': 0,\n",
    "  'id_284': 0,\n",
    "  'id_285': 0,\n",
    "  'id_286': 0,\n",
    "  'id_287': 0,\n",
    "  'id_288': 0,\n",
    "  'id_289': 0,\n",
    "  'id_290': 0,\n",
    "  'id_291': 0,\n",
    "  'id_292': 0,\n",
    "  'id_293': 0,\n",
    "  'id_294': 0,\n",
    "  'id_295': 0,\n",
    "  'id_296': 0,\n",
    "  'id_297': 1,\n",
    "  'id_299': 0,\n",
    "  'id_300': 0,\n",
    "  'id_301': 0,\n",
    "  'id_302': 0,\n",
    "  'id_303': 0,\n",
    "  'id_304': 0,\n",
    "  'id_305': 1,\n",
    "  'id_307': 0,\n",
    "  'id_308': 0,\n",
    "  'id_309': 0,\n",
    "  'id_310': 0,\n",
    "  'id_311': 0,\n",
    "  'id_312': 0,\n",
    "  'id_313': 0,\n",
    "  'id_314': 0,\n",
    "  'id_315': 0,\n",
    "  'id_316': 0,\n",
    "  'id_317': 0,\n",
    "  'id_318': 0,\n",
    "  'id_319': 1,\n",
    "  'id_321': 0,\n",
    "  'id_322': 0,\n",
    "  'id_323': 0,\n",
    "  'id_324': 0,\n",
    "  'id_325': 1,\n",
    "  'id_327': 0,\n",
    "  'id_328': 0,\n",
    "  'id_329': 1,\n",
    "  'id_331': 0,\n",
    "  'id_332': 0,\n",
    "  'id_333': 0,\n",
    "  'id_334': 0,\n",
    "  'id_335': 0,\n",
    "  'id_336': 0,\n",
    "  'id_337': 0,\n",
    "  'id_338': 0,\n",
    "  'id_339': 0,\n",
    "  'id_340': 0,\n",
    "  'id_341': 0,\n",
    "  'id_342': 0,\n",
    "  'id_343': 0,\n",
    "  'id_344': 0,\n",
    "  'id_345': 0,\n",
    "  'id_346': 0,\n",
    "  'id_347': 0,\n",
    "  'id_348': 0,\n",
    "  'id_349': 0,\n",
    "  'id_350': 0,\n",
    "  'id_351': 0,\n",
    "  'id_352': 0,\n",
    "  'id_353': 0,\n",
    "  'id_354': 0,\n",
    "  'id_355': 0,\n",
    "  'id_356': 0,\n",
    "  'id_357': 0,\n",
    "  'id_358': 0,\n",
    "  'id_359': 0,\n",
    "  'id_360': 0,\n",
    "  'id_361': 0,\n",
    "  'id_362': 0,\n",
    "  'id_363': 0,\n",
    "  'id_364': 0,\n",
    "  'id_365': 0,\n",
    "  'id_366': 1,\n",
    "  'id_369': 0,\n",
    "  'id_370': 0,\n",
    "  'id_371': 0,\n",
    "  'id_372': 0,\n",
    "  'id_373': 0,\n",
    "  'id_374': 0,\n",
    "  'id_375': 0,\n",
    "  'id_376': 0,\n",
    "  'id_377': 0,\n",
    "  'id_378': 0,\n",
    "  'id_379': 0,\n",
    "  'id_380': 0,\n",
    "  'id_381': 0,\n",
    "  'id_382': 0,\n",
    "  'id_383': 0,\n",
    "  'id_384': 0,\n",
    "  'id_385': 0,\n",
    "  'id_386': 0,\n",
    "  'id_387': 0,\n",
    "  'id_388': 1,\n",
    "  'id_390': 1,\n",
    "  'id_392': 0,\n",
    "  'id_393': 0,\n",
    "  'id_394': 0,\n",
    "  'id_395': 0,\n",
    "  'id_396': 1,\n",
    "  'id_398': 1,\n",
    "  'id_400': 0,\n",
    "  'id_401': 1,\n",
    "  'id_403': 0,\n",
    "  'id_404': 1,\n",
    "  'id_406': 0,\n",
    "  'id_407': 0,\n",
    "  'id_408': 0,\n",
    "  'id_409': 0,\n",
    "  'id_410': 0,\n",
    "  'id_411': 0,\n",
    "  'id_412': 0,\n",
    "  'id_413': 1,\n",
    "  'id_415': 0,\n",
    "  'id_416': 0,\n",
    "  'id_417': 0,\n",
    "  'id_418': 0,\n",
    "  'id_419': 0,\n",
    "  'id_420': 0,\n",
    "  'id_421': 1,\n",
    "  'id_423': 0,\n",
    "  'id_424': 0,\n",
    "  'id_425': 0,\n",
    "  'id_426': 0,\n",
    "  'id_427': 0,\n",
    "  'id_428': 0,\n",
    "  'id_429': 0,\n",
    "  'id_430': 0,\n",
    "  'id_431': 0,\n",
    "  'id_432': 0,\n",
    "  'id_433': 1,\n",
    "  'id_435': 0,\n",
    "  'id_436': 0,\n",
    "  'id_437': 0,\n",
    "  'id_438': 0,\n",
    "  'id_439': 0,\n",
    "  'id_440': 1,\n",
    "  'id_442': 0,\n",
    "  'id_443': 0,\n",
    "  'id_444': 0,\n",
    "  'id_445': 0,\n",
    "  'id_446': 0,\n",
    "  'id_447': 0,\n",
    "  'id_448': 0,\n",
    "  'id_449': 0,\n",
    "  'id_450': 1,\n",
    "  'id_452': 0,\n",
    "  'id_453': 0,\n",
    "  'id_454': 0,\n",
    "  'id_455': 0,\n",
    "  'id_456': 0,\n",
    "  'id_457': 0,\n",
    "  'id_458': 0,\n",
    "  'id_459': 0,\n",
    "  'id_460': 0,\n",
    "  'id_461': 0,\n",
    "  'id_462': 0,\n",
    "  'id_463': 1,\n",
    "  'id_465': 0,\n",
    "  'id_466': 0,\n",
    "  'id_467': 0,\n",
    "  'id_468': 1,\n",
    "  'id_470': 0,\n",
    "  'id_471': 0,\n",
    "  'id_472': 0,\n",
    "  'id_473': 0,\n",
    "  'id_474': 0,\n",
    "  'id_475': 0,\n",
    "  'id_476': 0,\n",
    "  'id_477': 1,\n",
    "  'id_479': 0,\n",
    "  'id_480': 0,\n",
    "  'id_481': 0,\n",
    "  'id_482': 0,\n",
    "  'id_483': 0,\n",
    "  'id_484': 0,\n",
    "  'id_485': 0,\n",
    "  'id_486': 0,\n",
    "  'id_487': 0,\n",
    "  'id_488': 0,\n",
    "  'id_489': 0,\n",
    "  'id_490': 0,\n",
    "  'id_491': 0,\n",
    "  'id_492': 0,\n",
    "  'id_493': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f4f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(filepath, model):\n",
    "    file = h5py.File(filepath,'w')\n",
    "    weight = model.get_weights()\n",
    "    for i in range(len(weight)):\n",
    "        file.create_dataset('weight'+str(i),data=weight[i])\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7683747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath, model):\n",
    "    file=h5py.File(filepath,'r')\n",
    "    weight = []\n",
    "    for i in range(len(file.keys())):\n",
    "        weight.append(file['weight'+str(i)][:])\n",
    "    model.set_weights(weight)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a510d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimension=np.load('/Users/boabangfrancis/data_action/' + train)\n",
    "#dim_shape=(dimension.shape[0],dimension.shape[1], dimension.shape[2])\n",
    "labelssorted=dict(sorted(labels.items()))\n",
    "params = {'dim': (10, 240, 320),\n",
    "          'batch_size': 10,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 3,\n",
    "          'folder': 'data_action/',\n",
    "          'shuffle': True}\n",
    "  \n",
    "#y = tf.keras.layers.UpSampling3D(size=10)(normals)   \n",
    "    \n",
    "train_generator = DataGenerator(normals[101:], label, **params)\n",
    "val_generator = DataGenerator(normals[1:100], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb08bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from padam import Padam\n",
    "from amsgrad import AMSGrad\n",
    "from proposed_ASGD import Proposed_ASGD\n",
    "#learning_rate=0.00001\n",
    "#learning_rate_min=0.00001\n",
    "#learning_rate_max=0.001\n",
    "optim_array=[ 'padam', 'adam', 'proposed_ASGD',  'amsgrad', 'sgd']\n",
    "history={}\n",
    "for optimizer in optim_array:\n",
    "    op=optim_params[optimizer]\n",
    "    model = create_model(240, 320) \n",
    "    logfile= 'log_' + optimizer +'_' + '.csv'\n",
    "    #op['lr']=op['lr']\n",
    "   # learning_rate_min=op['lr_min']\n",
    "    \n",
    "    if optimizer == 'proposed_ASGD':\n",
    "        learning_rate_max=op['lr_max']\n",
    "        learning_rate_min=op['lr_min']\n",
    "        optim = Proposed_ASGD(learning_rate_min=learning_rate_min,learning_rate_max=learning_rate_max, beta1=op['b1'], beta2=op['b2'])\n",
    "        \n",
    "    elif optimizer == 'padam':\n",
    "        learning_rate_max=op['lr_max']\n",
    "        optim = Padam(learning_rate=learning_rate_max, p=op['p'], beta1=op['b1'], beta2=op['b2'])\n",
    "    elif optimizer == 'adam':\n",
    "        learning_rate_min=op['lr_min']\n",
    "        optim = tf.train.AdamOptimizer(learning_rate=learning_rate_min, beta1=op['b1'], beta2=op['b2'])\n",
    "    elif optimizer == 'adamw':\n",
    "        learning_rate_min=op['lr_min']\n",
    "            # adamw = tf.contrib.opt.extend_with_decoupled_weight_decay(tf.train.AdamOptimizer)\n",
    "        optim = tf.contrib.opt.AdamWOptimizer(weight_decay=op['weight_decay'], learning_rate=learning_rate_min,  beta1=op['b1'], beta2=op['b2'])\n",
    "    elif optimizer == 'amsgrad':\n",
    "        learning_rate_min=op['lr_min']\n",
    "        optim = AMSGrad(learning_rate=learning_rate_min, beta1=op['b1'], beta2=op['b2'])\n",
    "    elif optimizer == 'sgd':\n",
    "        learning_rate_max=op['lr_max']\n",
    "        optim = tf.train.MomentumOptimizer(learning_rate=learning_rate_max, momentum=op['m'])\n",
    "       \n",
    "    model.compile(optimizer=optim, loss='binary_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "    csv_logger = CSVLogger(logfile, append=True, separator=';')\n",
    "        #model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=learning_rate), metrics=metrics)\n",
    "    model.fit_generator(generator=train_generator, validation_data=val_generator, epochs=100, shuffle=False, verbose=1, callbacks = [csv_logger])\n",
    "    scores = model.evaluate_generator(val_generator, verbose=1)\n",
    "    print(\"Final test loss and accuracy:\", scores)\n",
    "    #save_model(save_model_filepath, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357710d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f22db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e58fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3475a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6b19f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
